{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIYbZxtBYXRU5vAjbL+V29",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Angel-ica/AIRBNB-DATASET/blob/main/Linear_Regression/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HH2nm0nM3qsh",
        "outputId": "3fb6d38d-ba6a-49da-b953-43a3efc54f87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/gdrive/MyDrive/project_folder/AIRBNB-DATASET"
      ],
      "metadata": {
        "id": "l0ezrKUE4As_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5J_vDebT3CvX"
      },
      "outputs": [],
      "source": [
        "'''here, we're using GridSearchcv to tune the hyperparameters of some linear models and then return the best model and it's hyperparameters.'''\n",
        "import sys\n",
        "# sys.path.insert(0,\"/Users/angelicaaluo/Airbnb/AIRBNB-DATASET/\")\n",
        "import pandas  as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import joblib\n",
        "import json\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn. ensemble import GradientBoostingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from pathlib import Path\n",
        "\n",
        "df= pd.read_csv('/content/gdrive/MyDrive/project_folder/AIRBNB-DATASET/airbnb-property-listings/tabular_data/clean_data.csv')\n",
        "df.drop('Unnamed: 19',axis=1,inplace=True)  \n",
        "# X = df.select_dtypes(include=['int','float'])\n",
        "X=df[[\"beds\",\"bedrooms\",\"amenities_count\",\"Location_rating\",\"Cleanliness_rating\",\"bathrooms\",\"Value_rating\"]]\n",
        "X = df.select_dtypes(include=['int','float'])\n",
        "y=df[\"Price_Night\"]\n",
        "\n",
        "print(globals().keys())\n",
        "if \"Beds\" in globals().keys():\n",
        "    del Beds\n",
        "\n",
        "# MinMaxScaler().fit_transform(X_train)\n",
        "\n",
        "model_hyperparam_distribution={\n",
        "LinearRegression: {\n",
        "    'fit_intercept': [True, False],\n",
        "    # 'normalize': [True, False],\n",
        "    'copy_X': [True, False],\n",
        "    'n_jobs': [None, 1, 2, 3, 4],\n",
        "    # 'random_state': [42, 56, 71, 93]\n",
        "},\n",
        "\n",
        "DecisionTreeRegressor:{\n",
        "    'max_depth': [3,5,7,10],\n",
        "    'min_samples_leaf': [10, 20, 30, 50],\n",
        "    'min_samples_split': [2, 5, 10, 20],\n",
        "    'max_leaf_nodes': [5, 10, 15, 20],\n",
        "    'max_features': [1.0, 'sqrt', 'log2', None],\n",
        "    # 'criterion': ['mse', 'mae'],\n",
        "    # 'criterion' :['poisson', 'squared_error', 'absolute_error', 'friedman_mse'],\n",
        "    'splitter': ['best', 'random'],\n",
        "    'random_state': [42, 56, 71, 93]\n",
        "},\n",
        "\n",
        "GradientBoostingRegressor:{\n",
        "    'learning_rate': [0.01, 0.1, 0.5, 1],\n",
        "    'n_estimators': [50, 100, 200, 500],\n",
        "    'max_depth': [3, 5, 8, 10],\n",
        "    'min_samples_leaf': [10, 20, 30, 40],\n",
        "    'min_samples_split': [2, 5, 10, 20],\n",
        "    #'max_leaf_nodes': [5,15, 20, 25],\n",
        "    'max_features': [ 'sqrt', 'log2', None],\n",
        "    #'loss': ['absolute_error', 'squared_error', 'huber', 'quantile'],\n",
        "    #'random_state': [42, 56, 71, 93]\n",
        "},\n",
        "\n",
        "SGDRegressor:{\n",
        "    'loss': ['squared_error', 'epsilon_insensitive', 'huber', 'squared_epsilon_insensitive'],\n",
        "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
        "    'alpha': [0.001, 0.03, 0.63, 1],\n",
        "    'l1_ratio': [ 0.3, 0.7],\n",
        "    'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
        "    'max_iter': [250, 750, 500, 1000]\n",
        "}\n",
        "\n",
        "}\n",
        "\n",
        "def tune_regression_model_hyperparameters(features, label, model_hyperparam_distribution):\n",
        "    features = X\n",
        "    label=y\n",
        "\n",
        "    for md,hp in model_hyperparam_distribution.items():\n",
        "        model = md()\n",
        "        hyper_param=hp\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.5, random_state=42)\n",
        "        MinMaxScaler().fit_transform(X_train)\n",
        "        grid_search =GridSearchCV(estimator=model,param_grid=hp,verbose=5,cv=6,refit=True)\n",
        "        grid_search.fit(X_train,y_train) \n",
        "        tuned_model=grid_search.best_estimator_\n",
        "        tuned_parameters=grid_search.best_params_\n",
        "        y_pred = grid_search.predict(X_test)\n",
        "        eval_metrics={\n",
        "            'MAE %.2f: ':{mean_absolute_error(y_test,y_pred)},\n",
        "            'MSE :': {mean_squared_error(y_test,y_pred)},\n",
        "            'r2_score :' : {r2_score(y_test,y_pred)},\n",
        "            'RMSE:': {mean_squared_error(y_test, y_pred)**0.5},\n",
        "            'Validation RMSE:': {mean_squared_error(y_val,(grid_search.predict(X_val)))**0.5}\n",
        "        }\n",
        "        \n",
        "        destination='/content/gdrive/MyDrive/project_folder/AIRBNB-DATASET/Linear_Regression /models/'\n",
        "        if not os.path.isdir(destination):\n",
        "            os.mkdir(destination)\n",
        "        model_destination = f'{destination}/GridSearchcv'\n",
        "        if not os.path.isdir(model_destination):\n",
        "            os.mkdir(model_destination)\n",
        "        model_final_path=f'{model_destination}/{model}'\n",
        "        save_model(tuned_model,tuned_parameters,eval_metrics,model_final_path)\n",
        "    #print(tuned_model,tuned_parameters,metrics)\n",
        "    return tuned_model,tuned_parameters,eval_metrics\n",
        "\n",
        "def save_model(model,hyper_parameters,metrics,folder):\n",
        "    if not os.path.isdir(folder):\n",
        "        os.mkdir(folder)\n",
        "    model_path = f\"{folder}/model.joblib\"\n",
        "    joblib.dump(model,model_path)\n",
        "\n",
        "    hyperparameter_path = f'{folder}/hyperparameter.json'\n",
        "    with open (hyperparameter_path, 'w') as hp:\n",
        "        json.dump(str(hyper_parameters),hp)\n",
        "\n",
        "    eval_path = folder + '/metrics.json'\n",
        "    with open (eval_path, 'w') as ep:\n",
        "        json.dump(str(metrics),ep)\n",
        "\n",
        "def find_best_model():\n",
        "    all_metrics_files = list(Path('./models/GridSearchcv/').glob('**/*metrics.json'))\n",
        "    all_metric_data=[]\n",
        "    for metric_file in all_metrics_files:\n",
        "        with open(metric_file,'r') as f:\n",
        "            metric_data=json.load(f)\n",
        "            all_metric_data.append(metric_data)\n",
        "    best_score=max(all_metric_data)\n",
        "    for score in all_metric_data:\n",
        "        if score==best_score:\n",
        "            best_tuned_model=str(metric_file).split('/')[-2]\n",
        "            best_tuned_model_path= f'./models/GridSearchcv/{best_tuned_model}'\n",
        "            best_model_name=joblib.load(f'{best_tuned_model_path}/model.joblib')\n",
        "            with open(f'{best_tuned_model_path}/hyperparameter.json', 'r') as hp:\n",
        "                best_model_hp=json.load(hp)\n",
        "            with open(f'{best_tuned_model_path}/metrics.json', 'r') as score:\n",
        "                best_model_score=json.load(score)\n",
        "            return best_model_name,best_model_hp,best_model_score\n",
        "\n",
        "\n",
        "\n",
        "tune_regression_model_hyperparameters(X,y,model_hyperparam_distribution)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''The hyperparameters used in this cell were optimized by gridsearchcv in the above cell. \n",
        "Note that it did not return the best score but the scores from linear reg showed that the model was over fitting the data.'''\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split,KFold,StratifiedKFold\n",
        "from sklearn.metrics import r2_score, mean_absolute_error,mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "\n",
        "df= pd.read_csv('/content/gdrive/MyDrive/project_folder/AIRBNB-DATASET/airbnb-property-listings/tabular_data/clean_data.csv')\n",
        "df.drop('Unnamed: 19',axis=1,inplace=True)  \n",
        "X=df[[\"beds\",\"bedrooms\",\"amenities_count\",\"Location_rating\",\"Cleanliness_rating\",\"bathrooms\"]]\n",
        "X = df.select_dtypes(include=['int','float'])\n",
        "y=df[\"Price_Night\"]\n",
        "\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n",
        "X_train,X_val,y_train,y_val=train_test_split(X_train,y_train,test_size=0.5,random_state=42)\n",
        "\n",
        "# mx=MinMaxScaler()\n",
        "# X_train=mx.fit_transform(X_train)\n",
        "# X_test=mx.transform(X_test)\n",
        "\n",
        "gd=GradientBoostingRegressor(learning_rate= 0.1, max_depth= 8, max_features= None, min_samples_leaf=10, min_samples_split= 5, n_estimators=500)\n",
        "gd.fit(X_train,y_train)\n",
        "y_pred=gd.predict(X_test)\n",
        "eval_metrics={\n",
        "            'MAE : ':{mean_absolute_error(y_test,y_pred)},\n",
        "            'MSE :': {mean_squared_error(y_test,y_pred)},\n",
        "            'r2_score :' : {r2_score(y_test,y_pred)},\n",
        "            'RMSE:': {mean_squared_error(y_test, y_pred)**0.5},\n",
        "            'Validation RMSE:': {mean_squared_error(y_val,(gd.predict(X_val)))**0.5}\n",
        "        }\n",
        "print(eval_metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5h7EpEYGEeis",
        "outputId": "99f5005e-e8ed-4196-8f55-744db3f9f4c3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'MAE : ': {8.748281785786913}, 'MSE :': {1402.4925315049504}, 'r2_score :': {0.9170122792731107}, 'RMSE:': {37.44986690904189}, 'Validation RMSE:': {38.3720737822272}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O438MP_tOrd3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}